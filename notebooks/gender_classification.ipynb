{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resemblyzer import preprocess_wav, VoiceEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import joblib\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../Downloads/gender_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeds', 'file_paths', 'gender', 'duration']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, duration, labels, paths = data['embeds'], data['duration'], data['gender'], data['file_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32122, 256), (32122,), (32122,), (32122,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, duration.shape, labels.shape, paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of data : 47.0 hours\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duration of data : {np.sum(duration)//3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = [p.split('/')[-5] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bucket_data', 'openslr_kn', 'openslr_ta', 'openslr_te', 'tarini', 'youtube'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(source_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.where(labels=='male', 0, labels)\n",
    "labels = np.where(labels=='female', 1, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    data_df['feature_'+str(i)] = embeddings[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32122, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_246</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082214</td>\n",
       "      <td>0.070557</td>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025604</td>\n",
       "      <td>0.168945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.122986        0.0   0.172363        0.0   0.000000        0.0   \n",
       "1   0.052094        0.0   0.055695        0.0   0.002235        0.0   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_246  feature_247  \\\n",
       "0   0.082214   0.070557   0.041473   0.000000  ...     0.135132          0.0   \n",
       "1   0.000000   0.006420   0.042542   0.008408  ...     0.011482          0.0   \n",
       "\n",
       "   feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
       "0     0.069702      0.00000          0.0     0.041168     0.000000   \n",
       "1     0.110046      0.03244          0.0     0.025604     0.168945   \n",
       "\n",
       "   feature_253  feature_254  feature_255  \n",
       "0          0.0     0.073486          0.0  \n",
       "1          0.0     0.018845          0.0  \n",
       "\n",
       "[2 rows x 256 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.insert(loc=0, column='labels', value=labels)\n",
    "data_df.insert(loc=1, column='duration', value=duration)\n",
    "data_df.insert(loc=2, column='source_name', value=source_name)\n",
    "data_df.insert(loc=3,column='file_paths', value=paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32122, 260)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>duration</th>\n",
       "      <th>source_name</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_246</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.133313</td>\n",
       "      <td>openslr_kn</td>\n",
       "      <td>/Users/neerajchhimwal/ekstep-speech-recognitio...</td>\n",
       "      <td>0.122986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.240000</td>\n",
       "      <td>openslr_kn</td>\n",
       "      <td>/Users/neerajchhimwal/ekstep-speech-recognitio...</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.03244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025604</td>\n",
       "      <td>0.168945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels   duration source_name  \\\n",
       "0       0   2.133313  openslr_kn   \n",
       "1       0  10.240000  openslr_kn   \n",
       "\n",
       "                                          file_paths  feature_0  feature_1  \\\n",
       "0  /Users/neerajchhimwal/ekstep-speech-recognitio...   0.122986        0.0   \n",
       "1  /Users/neerajchhimwal/ekstep-speech-recognitio...   0.052094        0.0   \n",
       "\n",
       "   feature_2  feature_3  feature_4  feature_5  ...  feature_246  feature_247  \\\n",
       "0   0.172363        0.0   0.000000        0.0  ...     0.135132          0.0   \n",
       "1   0.055695        0.0   0.002235        0.0  ...     0.011482          0.0   \n",
       "\n",
       "   feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
       "0     0.069702      0.00000          0.0     0.041168     0.000000   \n",
       "1     0.110046      0.03244          0.0     0.025604     0.168945   \n",
       "\n",
       "   feature_253  feature_254  feature_255  \n",
       "0          0.0     0.073486          0.0  \n",
       "1          0.0     0.018845          0.0  \n",
       "\n",
       "[2 rows x 260 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='duration', ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data_df.duration, log_scale=True, fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df[data_df.duration<=2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32122, 260)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_v1 = data_df[~(data_df.duration<=2)]\n",
    "data_v1 = data_df.copy()\n",
    "data_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data_v1.duration, log_scale=True, fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of data after removing utterances less than 2 sec : 47.0 hours\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duration of data after removing utterances less than 2 sec : {np.sum(data_v1.duration)//3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_name\n",
       "bucket_data     3.0\n",
       "openslr_kn      3.0\n",
       "openslr_ta      3.0\n",
       "openslr_te      2.0\n",
       "tarini         20.0\n",
       "youtube        13.0\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v1.groupby(['source_name'])['duration'].agg('sum')//3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test on youtube and train on rest of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['openslr_kn', 'bucket_data', 'openslr_ta', 'youtube', 'tarini',\n",
       "       'openslr_te'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v1.source_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_v1[~(data_v1.source_name=='youtube')].drop(['labels', 'source_name', 'file_paths', 'duration'], axis=1).values\n",
    "y_train = data_v1[~(data_v1.source_name=='youtube')]['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21488, 256), (21488,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes = data_v1[~(data_v1.source_name=='youtube')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7942\n",
       "1    2692\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v1[(data_v1.source_name=='youtube')]['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_female = data_v1[(data_v1.source_name=='youtube') & (data_v1.labels==1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_male = data_v1[(data_v1.source_name=='youtube') & (data_v1.labels==0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_male_50 = youtube_male.loc[np.random.choice(youtube_male.index, 2692, replace=False)]\n",
    "test_50 = pd.concat([youtube_male_50, youtube_female]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_male_25 = youtube_male.loc[np.random.choice(youtube_male.index, 897, replace=False)]\n",
    "test_25 = pd.concat([youtube_male_25, youtube_female]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_75 = pd.concat([youtube_male, youtube_female]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankurdhuriya/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "skFold = StratifiedKFold(n_splits=5, shuffle=False, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [01:55, 23.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 242 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = []\n",
    "for train_ix, val_ix in tqdm(skFold.split(X_train, y_train)):\n",
    "    \n",
    "    train_X, val_X = X_train[train_ix], X_train[val_ix]\n",
    "    train_y, val_y = y_train[train_ix], y_train[val_ix]\n",
    "    #model\n",
    "    clf_SVC = SVC(kernel='rbf', gamma=0.01, C=100, random_state=2020, probability=True) \n",
    "    #fit\n",
    "    clf_SVC.fit(train_X, train_y)\n",
    "    #predict\n",
    "    pred = clf_SVC.predict(val_X)\n",
    "    pred_proba = clf_SVC.predict_proba(val_X)\n",
    "    cv_scores.append(f1_score(val_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename):\n",
    "    return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(clf_SVC, filename='clf_svc.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on validation : 0.9846072026809803 +/- 0.012771463760817241\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score on validation : {np.mean(cv_scores)} +/- {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_25 = test_25.drop(['labels', 'source_name', 'file_paths', 'duration'], axis=1).values\n",
    "y_test_25 = test_25['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 864,   33],\n",
       "       [ 147, 2545]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_25 = clf_SVC.predict(X_test_25)\n",
    "\n",
    "confusion_matrix(y_test_25, y_pred_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91       897\n",
      "           1       0.99      0.95      0.97      2692\n",
      "\n",
      "    accuracy                           0.95      3589\n",
      "   macro avg       0.92      0.95      0.94      3589\n",
      "weighted avg       0.95      0.95      0.95      3589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_25, y_pred_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_50 = test_50.drop(['labels', 'source_name', 'file_paths', 'duration'], axis=1).values\n",
    "y_test_50 = test_50['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2608,   84],\n",
       "       [ 147, 2545]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_50 = clf_SVC.predict(X_test_50)\n",
    "\n",
    "confusion_matrix(y_test_50, y_pred_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      2692\n",
      "           1       0.97      0.95      0.96      2692\n",
      "\n",
      "    accuracy                           0.96      5384\n",
      "   macro avg       0.96      0.96      0.96      5384\n",
      "weighted avg       0.96      0.96      0.96      5384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_50, y_pred_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_75 = test_75.drop(['labels', 'source_name', 'file_paths', 'duration'], axis=1).values\n",
    "y_test_75 = test_75['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7715,  227],\n",
       "       [ 147, 2545]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_75 = clf_SVC.predict(X_test_75)\n",
    "\n",
    "confusion_matrix(y_test_75, y_pred_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      7942\n",
      "           1       0.92      0.95      0.93      2692\n",
      "\n",
      "    accuracy                           0.96     10634\n",
      "   macro avg       0.95      0.96      0.95     10634\n",
      "weighted avg       0.97      0.96      0.96     10634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_75, y_pred_75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('wrong_predictions.csv', mode='w+')\n",
    "print(\"file_path,predicted_label,correct_label\", file=f)\n",
    "for row_index, (prediction, label) in enumerate(zip (y_pred_75, y_test_75)):\n",
    "    if prediction != label:\n",
    "        print(test_75.loc[row_index]['file_paths'],prediction,label,sep=\",\",file=f)\n",
    "#         print('Path', test_75.loc[row_index]['file_paths'], 'has been classified as ', prediction, 'and should be ', label)\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.youtube.com/watch?v=0pN2QCH3Nmg',\n",
       " 'https://www.youtube.com/watch?v=1w5wcE-KozI',\n",
       " 'https://www.youtube.com/watch?v=44w4BGfFj9M',\n",
       " 'https://www.youtube.com/watch?v=4P5bAA1MBLY',\n",
       " 'https://www.youtube.com/watch?v=4ZOCKkP0khM',\n",
       " 'https://www.youtube.com/watch?v=5OiWwuauOew',\n",
       " 'https://www.youtube.com/watch?v=64uM9b-BFM0',\n",
       " 'https://www.youtube.com/watch?v=7CLm8o3hOvk',\n",
       " 'https://www.youtube.com/watch?v=7a0wQdo7wn0',\n",
       " 'https://www.youtube.com/watch?v=9TzCwCVAbq4',\n",
       " 'https://www.youtube.com/watch?v=A9hFXAbV55U',\n",
       " 'https://www.youtube.com/watch?v=B7HWZiUfFdM',\n",
       " 'https://www.youtube.com/watch?v=BPA6OxSAWK8',\n",
       " 'https://www.youtube.com/watch?v=CFfR3Gsya8Q',\n",
       " 'https://www.youtube.com/watch?v=CG3o9RJAUlI',\n",
       " 'https://www.youtube.com/watch?v=E3z3Ebx9QGE',\n",
       " 'https://www.youtube.com/watch?v=EXS9XfcAwAI',\n",
       " 'https://www.youtube.com/watch?v=GQxueON7Pc8',\n",
       " 'https://www.youtube.com/watch?v=IGN95uuTqqk',\n",
       " 'https://www.youtube.com/watch?v=J9fGHpBPR5A',\n",
       " 'https://www.youtube.com/watch?v=Jol3RyxxKT0',\n",
       " 'https://www.youtube.com/watch?v=M_S0XFvlcAo',\n",
       " 'https://www.youtube.com/watch?v=NmDmQpyeAbE',\n",
       " 'https://www.youtube.com/watch?v=P-Oc0cEg6kU',\n",
       " 'https://www.youtube.com/watch?v=QZ1ObE3yyvQ',\n",
       " 'https://www.youtube.com/watch?v=SagMWkyock4',\n",
       " 'https://www.youtube.com/watch?v=TPupLSEoxLY',\n",
       " 'https://www.youtube.com/watch?v=TphPRZnjvQs',\n",
       " 'https://www.youtube.com/watch?v=UrRkyCOlzSo',\n",
       " 'https://www.youtube.com/watch?v=YbdLUfKVEyI',\n",
       " 'https://www.youtube.com/watch?v=YlpKI3n6lEs',\n",
       " 'https://www.youtube.com/watch?v=YpzVfln8YdQ',\n",
       " 'https://www.youtube.com/watch?v=_53bE2kr_mU',\n",
       " 'https://www.youtube.com/watch?v=_jOwXbpxw8c',\n",
       " 'https://www.youtube.com/watch?v=bTLwKS4qUZ4',\n",
       " 'https://www.youtube.com/watch?v=cq8k-Xw8FO0',\n",
       " 'https://www.youtube.com/watch?v=dLDHT_nkQ_g',\n",
       " 'https://www.youtube.com/watch?v=e03MhJdIbA4',\n",
       " 'https://www.youtube.com/watch?v=e93wapN1-eQ',\n",
       " 'https://www.youtube.com/watch?v=epR8-fFE87Y',\n",
       " 'https://www.youtube.com/watch?v=fAw7_DtUp98',\n",
       " 'https://www.youtube.com/watch?v=fLm40CSzveM',\n",
       " 'https://www.youtube.com/watch?v=fY6A75ptmmQ',\n",
       " 'https://www.youtube.com/watch?v=fs4d1STt8pA',\n",
       " 'https://www.youtube.com/watch?v=ikk7HWlXXRc',\n",
       " 'https://www.youtube.com/watch?v=kYDnKpgPJw8',\n",
       " 'https://www.youtube.com/watch?v=lwqC_Wboqo8',\n",
       " 'https://www.youtube.com/watch?v=lz50AjvKUb8',\n",
       " 'https://www.youtube.com/watch?v=m0173WJUxEk',\n",
       " 'https://www.youtube.com/watch?v=mEn-RQTMKVI',\n",
       " 'https://www.youtube.com/watch?v=mLDHk4uIPp0',\n",
       " 'https://www.youtube.com/watch?v=nP6wjbOQBQU',\n",
       " 'https://www.youtube.com/watch?v=n_9Yd7Ny8TY',\n",
       " 'https://www.youtube.com/watch?v=qQp283dw2vw',\n",
       " 'https://www.youtube.com/watch?v=rQ8hB-Pu6wA',\n",
       " 'https://www.youtube.com/watch?v=rR2OP9puxlk',\n",
       " 'https://www.youtube.com/watch?v=rWsuTAwQ-pE',\n",
       " 'https://www.youtube.com/watch?v=sZYoBSMMy_k',\n",
       " 'https://www.youtube.com/watch?v=ses2ulQvYM4',\n",
       " 'https://www.youtube.com/watch?v=sgk0fm42TEk',\n",
       " 'https://www.youtube.com/watch?v=usHLqWDxqSo',\n",
       " 'https://www.youtube.com/watch?v=vcxRAPUmg8g',\n",
       " 'https://www.youtube.com/watch?v=w4VI74xpvi4',\n",
       " 'https://www.youtube.com/watch?v=y3WGSLkgDUY',\n",
       " 'https://www.youtube.com/watch?v=yf6FIGW82wk',\n",
       " 'https://www.youtube.com/watch?v=ytvWx6zecSc',\n",
       " 'https://www.youtube.com/watch?v=zEYOJO5v2xY',\n",
       " 'https://www.youtube.com/watch?v=zgMtF2g9sDc'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([\"https://www.youtube.com/watch?v=\"+re.search(\"-id(.*).wav\", i).group(1) for i in pd.read_csv('wrong_predictions.csv')['file_path'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vakyansh_data = np.load('../Downloads/vakyansh_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeds', 'file_paths', 'gender', 'duration']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vakyansh_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, duration, labels, paths = vakyansh_data['embeds'], vakyansh_data['duration'], vakyansh_data['gender'], vakyansh_data['file_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2208, 256), (2208,), (2208,), (2208,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, duration.shape, labels.shape, paths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duration of data : 2.0 hours\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total duration of data : {np.sum(duration)//3600} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_name = [p.split('/')[-5] for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'crowdsourcesorted'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(source_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.where(labels=='male', 0, labels)\n",
    "labels = np.where(labels=='female', 1, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vakyansh_data_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(256):\n",
    "    vakyansh_data_df['feature_'+str(i)] = embeddings[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vakyansh_data_df.insert(loc=0, column='labels', value=labels)\n",
    "vakyansh_data_df.insert(loc=1, column='duration', value=duration)\n",
    "vakyansh_data_df.insert(loc=2, column='source_name', value=source_name)\n",
    "vakyansh_data_df.insert(loc=3,column='file_paths', value=paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 260)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vakyansh_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>duration</th>\n",
       "      <th>source_name</th>\n",
       "      <th>file_paths</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_246</th>\n",
       "      <th>feature_247</th>\n",
       "      <th>feature_248</th>\n",
       "      <th>feature_249</th>\n",
       "      <th>feature_250</th>\n",
       "      <th>feature_251</th>\n",
       "      <th>feature_252</th>\n",
       "      <th>feature_253</th>\n",
       "      <th>feature_254</th>\n",
       "      <th>feature_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.584000</td>\n",
       "      <td>crowdsourcesorted</td>\n",
       "      <td>/Users/ankurdhuriya/Downloads/crowdsourcesorte...</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>0.055176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.181312</td>\n",
       "      <td>crowdsourcesorted</td>\n",
       "      <td>/Users/ankurdhuriya/Downloads/crowdsourcesorte...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels  duration        source_name  \\\n",
       "0       0  3.584000  crowdsourcesorted   \n",
       "1       0  4.181312  crowdsourcesorted   \n",
       "\n",
       "                                          file_paths  feature_0  feature_1  \\\n",
       "0  /Users/ankurdhuriya/Downloads/crowdsourcesorte...   0.015381        0.0   \n",
       "1  /Users/ankurdhuriya/Downloads/crowdsourcesorte...   0.000000        0.0   \n",
       "\n",
       "   feature_2  feature_3  feature_4  feature_5  ...  feature_246  feature_247  \\\n",
       "0   0.012169        0.0        0.0   0.000442  ...          0.0          0.0   \n",
       "1   0.028992        0.0        0.0   0.000000  ...          0.0          0.0   \n",
       "\n",
       "   feature_248  feature_249  feature_250  feature_251  feature_252  \\\n",
       "0     0.127808          0.0          0.0     0.055969     0.055176   \n",
       "1     0.080627          0.0          0.0     0.045776     0.000000   \n",
       "\n",
       "   feature_253  feature_254  feature_255  \n",
       "0          0.0     0.000000          0.0  \n",
       "1          0.0     0.001284          0.0  \n",
       "\n",
       "[2 rows x 260 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vakyansh_data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vakyansh_X = vakyansh_data_df.drop(['labels', 'source_name', 'file_paths', 'duration'], axis=1).values\n",
    "vakyansh_y = vakyansh_data_df['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1558,   11],\n",
       "       [   4,  635]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vakyansh_y_pred = clf_SVC.predict(vakyansh_X)\n",
    "\n",
    "confusion_matrix(vakyansh_y, vakyansh_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1569\n",
      "           1       0.98      0.99      0.99       639\n",
      "\n",
      "    accuracy                           0.99      2208\n",
      "   macro avg       0.99      0.99      0.99      2208\n",
      "weighted avg       0.99      0.99      0.99      2208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(vakyansh_y, vakyansh_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
